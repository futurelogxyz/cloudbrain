---
author: DrJimFan on Twitter
title: Tweets From Jim (Linxi) Fan
category: #tweets
url: https://twitter.com/DrJimFan
---
![rw-book-cover](https://pbs.twimg.com/profile_images/1554922493101559808/SYSZhbcd.jpg)

## Metadata
- Author: @DrJimFan on Twitter
- Full Title: Tweets From Jim (Linxi) Fan
- Category: #tweets
- URL: https://twitter.com/DrJimFan

## Highlights
- AI is math. GPU is metal. Sitting between math and metal is a programming language. Ideally, it should feel like Python but scale like CUDA. I find two newcomers in this middle layer quite exciting:
  1. Bend: compiles modern high-level language features to native multi-threading on Apple Silicon or NVIDIA GPU. Supports difficult constructs like - lambdas with full closure, unrestricted recursion and branches, folds, ADTs, etc. Bend compiles to HVM2, a thread-safe runtime implemented in Rust.
  All open-source:
  - https://t.co/qb5VckRXVH
  - https://t.co/F3n8tw8pwy
  2. Mojo: a CUDA-flavored, Python like language the executes at C speed. Mojo is conceptually lower level than Bend and allows you to have stronger control over exactly how the parallelism is done. Especially suited for coding modern neural net accelerations by hand.
  - https://t.co/aYQ5LtgsVb
  - Llama2 in one Mojo source file: https://t.co/wW2ANhKPPT
  ![](https://pbs.twimg.com/media/GNy7Xatb0AASz-_.jpg)
  ![](https://pbs.twimg.com/media/GNy7bBDakAkf9ch.jpg) ([View Tweet](https://twitter.com/DrJimFan/status/1791514371086250291))
